foldername: yelp-b264-f8-test

# MLP: in 32+32+22 = 66
layers: [86, 32, 16, 8]

# GMF
num_factors: 8

# Data
# processed_data_root: /work3/s212784/data/processed/YELP/yelp_2_ctx/
processed_data_root: data/processed/YELP/CNCF/yelp5Context/

num_users: 215366
num_items: 95895
num_context: 21

num_workers: 2
cpu_nodes: 4

num_negative_instances_train: 4
num_negative_instances_test: 99

# Training
epochs: 100
batch_size: 264
lr: 0.001
optimizer: adam
dropout: 0

# Evaluation
topK: 10
evaluation_threads: 1
verbose: 1

# Loss
loss: BCE
