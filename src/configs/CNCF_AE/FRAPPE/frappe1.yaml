foldername: frappe-ae-c12-b256-f8

# MLP: in 32+32+9 (latent from AE)
layers: [73, 32, 16, 8]

# GMF
num_factors: 8

# Autoencoder
layers_ae: [12, 9]
ae_bottleneck: 9
ae_path: checkpoints/AE/frapppe5ContextV2/frappeV2-tanh/best_epoch.bin


# Data
# processed_data_root: data/processed/FRAPPE/CNCF/frappe5Context/
processed_data_root: /home/alexabades/recsys/data/processed/FRAPPE/CNCF/frapppe5ContextV2
num_users: 654
num_items: 1127
num_context: 21


# Training
epochs: 100
batch_size: 256
lr: 0.001
optimizer: adam
dropout: 0
num_negative_instances_train: 4

# Evaluation
topK: 10
evaluation_threads: 1
verbose: 1
num_negative_instances_test: 99  # All Data on the test set

# Loss
loss: BCE
