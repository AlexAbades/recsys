{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Analysis Cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/raw/CARS/Data_InCarMusic.xlsx'\n",
    "sheetname = 'ContextualRating'\n",
    "contextual_rating = pd.read_excel(filename, sheet_name=sheetname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read 4,012 rows from the \"ContextualRating\" Excel sheet\n",
      "Columns found: ['UserID', 'ItemID', ' Rating', 'DrivingStyle', 'landscape', 'mood', 'naturalphenomena ', 'RoadType', 'sleepiness', 'trafficConditions', 'weather']\n"
     ]
    }
   ],
   "source": [
    "print(f'Successfully read {len(contextual_rating):,} rows from the \"{sheetname}\" Excel sheet')\n",
    "print(f'Columns found: {contextual_rating.columns.tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read 139 rows from the \"Music Track\" Excel sheet\n",
      "Columns found: ['id', ' album', ' artist', ' title', ' mp3url', ' description', ' imageurl', ' category_id']\n"
     ]
    }
   ],
   "source": [
    "sheetname = 'Music Track'\n",
    "music_track = pd.read_excel(filename, sheet_name=sheetname)\n",
    "print(f'Successfully read {len(music_track):,} rows from the \"{sheetname}\" Excel sheet')\n",
    "print(f'Columns found: {music_track.columns.tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64 : ['UserID', 'ItemID', 'Rating']\n",
      "object : ['DrivingStyle', 'landscape', 'mood', 'naturalphenomena', 'RoadType', 'sleepiness', 'trafficConditions', 'weather']\n"
     ]
    }
   ],
   "source": [
    "for dtype, columns in contextual_rating.columns.to_series().groupby(contextual_rating.dtypes).groups.items():\n",
    "  print(dtype,':', list(columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserID                int64\n",
       "ItemID                int64\n",
       " Rating               int64\n",
       "DrivingStyle         object\n",
       "landscape            object\n",
       "mood                 object\n",
       "naturalphenomena     object\n",
       "RoadType             object\n",
       "sleepiness           object\n",
       "trafficConditions    object\n",
       "weather              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contextual_rating.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1001\n",
       "1       1001\n",
       "2       1001\n",
       "3       1001\n",
       "4       1001\n",
       "        ... \n",
       "4007    1042\n",
       "4008    1042\n",
       "4009    1042\n",
       "4010    1042\n",
       "4011    1042\n",
       "Name: UserID, Length: 4012, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contextual_rating['UserID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014\n",
      " 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028\n",
      " 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042]\n",
      "[715 267 294 259 674 285 279 754 694 251 250 702 714 762 275 295 757 727\n",
      " 256 726 730 718 745 263 732 683 751 719 716 737 273 676 760 748 744 743\n",
      " 690 736 269 296 711 741 759 257 739 271 266 735 701 747 264 700 721 708\n",
      " 758 687 287 262 707 677 679 270 282 678 286 696 261 272 699 697 253 276\n",
      " 268 691 260 681 689 709 693 252 725 682 280 680 734 729 249 692 723 686\n",
      " 675 248 297 752 728 254 756 278 293 710 703 761 712 277 695 753 717 291\n",
      " 705 740 724 733 704 750 684 281 283 255 274 746 706 292 288 713 749 284\n",
      " 731 289 755 698 720 265 290 258 722 742 685 738 688]\n",
      "[2 4 3 0 1 5]\n",
      "[nan 'relaxed driving' 'sport driving']\n",
      "[nan 'urban' 'mountains' 'country side' 'coast line']\n",
      "[nan 'sad' 'lazy' 'active' 'happy']\n",
      "[nan 'night' 'morning' 'day time' 'afternoon']\n",
      "[nan 'city' 'serpentine' 'highway']\n",
      "[nan 'sleepy' 'awake']\n",
      "[nan 'traffic jam' 'lots of cars' 'free road']\n",
      "['sunny' 'snowing' 'rainy' 'cloudy' nan]\n"
     ]
    }
   ],
   "source": [
    "for column in contextual_rating.columns:\n",
    "    print(contextual_rating[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextual_rating.columns = [x.strip() for x in contextual_rating.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64 : ['id', ' category_id']\n",
      "object : [' album', ' artist', ' title', ' mp3url', ' description', ' imageurl']\n"
     ]
    }
   ],
   "source": [
    "for dtype, columns in music_track.columns.to_series().groupby(music_track.dtypes).groups.items():\n",
    "  print(dtype,':', list(columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def _clean_columns(*args: str | List[str] | Tuple[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Cleans and consolidates column names from various input formats into a single list of strings.\n",
    "\n",
    "    This method processes input arguments that can either be individual string names of columns or collections\n",
    "    of strings (e.g., lists or tuples) containing multiple column names. It ensures that all column names are\n",
    "    collected into a flat list of strings, regardless of how they were passed to the method.\n",
    "\n",
    "    Parameters:\n",
    "    - args: Variable number of arguments, each can be a string representing a single column name or an iterable\n",
    "    (e.g., list or tuple) of strings representing multiple column names.\n",
    "\n",
    "    Returns:\n",
    "    - List[str]: A list containing all column names as strings, with individual string arguments and elements\n",
    "    from iterable arguments combined into a single list.\n",
    "    \"\"\"\n",
    "\n",
    "    clean_columns = []\n",
    "    for i in args:\n",
    "        if not i:\n",
    "            continue\n",
    "        if isinstance(i, str):\n",
    "            clean_columns.append(i)\n",
    "            continue\n",
    "        clean_columns.extend(i)\n",
    "    return clean_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3', '4']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = _clean_columns('1', ['2', '3'], None, '4')\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = None or {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The function you are trying to perform it is not yet developed. \n Posible encodings {self.current_encodings.keys()}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fnc \u001b[38;5;129;01min\u001b[39;00m b1:\n\u001b[1;32m      5\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m fnc \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m a1:\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe function you are trying to perform it is not yet developed. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Posible encodings \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mself.current_encodings.keys()}\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: The function you are trying to perform it is not yet developed. \n Posible encodings {self.current_encodings.keys()}"
     ]
    }
   ],
   "source": [
    "a1 = ['a', 'b', 'c']\n",
    "b1 = ['a', 'f']\n",
    "\n",
    "for fnc in b1:\n",
    "  if fnc not in a1:\n",
    "    raise ValueError('The function you are trying to perform it is not yet developed. \\n Posible encodings {self.current_encodings.keys()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_required_paremeters(**kwargs):\n",
    "        \"\"\"\n",
    "        Given a set of parameters, it throws an error if one of them is missing.\n",
    "        Minimum\n",
    "\n",
    "        Parameters:\n",
    "        \n",
    "        \"\"\"\n",
    "        print(kwargs)\n",
    "\n",
    "        # Check if any of the required parameters is None\n",
    "        missing_params = [\n",
    "            param for param, value in kwargs.items() if value is None\n",
    "        ]\n",
    "        if missing_params:\n",
    "            raise ValueError(\n",
    "                f\"Missing required parameters: {', '.join(missing_params)}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Given a set of parameters, it throws an error if one of them is missing.\n",
      "        Minimum\n",
      "\n",
      "        Parameters:\n",
      "        \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(check_required_paremeters.__doc__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
