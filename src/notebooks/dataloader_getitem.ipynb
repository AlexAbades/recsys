{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the above code, we have to initialize the class evry epoch, it fastens the things\n",
    "Learn abou how pytorch hadles the bath loader and see if it has to do with the _length__\n",
    "We can trigger the length with len(users)*(num_neg_instaces+1) and then use idx in __getitem_\n",
    "\n",
    "idx\n",
    "int(idx/num_negative_instaces)\n",
    "\n",
    "this will work only if the list is sorted, which it isn't.\n",
    "we can try to see if the idx position only starts one time at 0 and then call the method to generate data. we have to ensure that the paraleliation respects this wchich I doubt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample, seed\n",
    "\n",
    "def _create_negative_sample(train_data, test_data, user_column:str, item_column:str, num_samples:int=None):\n",
    "  # Set a random seed for reproducibility if needed\n",
    "  seed(42)\n",
    "\n",
    "  # Create set of all items\n",
    "  total_items = set(test_data[item_column].unique()) | set(train_data[item_column].unique())\n",
    "  \n",
    "  # Creating a dictionary to keep track of items each user has interacted with in train_data\n",
    "  items_per_user_train = train_data.groupby(user_column)[item_column].apply(set).to_dict()\n",
    "  items_per_user_test = test_data.groupby(user_column)[item_column].apply(set).to_dict()\n",
    "  \n",
    "  negative_samples = []\n",
    "\n",
    "  for index, row in test_data.iterrows():\n",
    "    user = row[user_column]\n",
    "    item = row[item_column]\n",
    "    \n",
    "    # Get interacted items from both train and test data, or an empty set if the user doesn't exist\n",
    "    items_train = items_per_user_train.get(user, set())\n",
    "    items_test = items_per_user_test.get(user, set())\n",
    "    \n",
    "    interacted_items = items_train | items_test\n",
    "    non_interacted_items = list(total_items - interacted_items)\n",
    "    \n",
    "    if num_samples and len(non_interacted_items) >= num_samples:\n",
    "      pool_of_items = sample(non_interacted_items, num_samples)\n",
    "    else: \n",
    "      pool_of_items = non_interacted_items\n",
    "    \n",
    "    \n",
    "    negative_samples.append([(user, item)] + pool_of_items)\n",
    "\n",
    "  return negative_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "def create_negative_sample(train_data, test_data, user_column:str, item_column:str, num_samples:int=None):\n",
    "  train_data_grouped = train_data.groupby([user_column, item_column]).count()\n",
    "  total_items = set(test_data[item_column].unique()) | set(train_data[item_column].unique())\n",
    "  negative_samples = []\n",
    "\n",
    "  for row in test_data.iterrows():\n",
    "    user = int(row[1][user_column])\n",
    "    item = int(row[1][item_column])\n",
    "    items_train = set(train_data_grouped.loc[user].index)\n",
    "    items_test = set(test_data[test_data[user_column] == user][item_column])\n",
    "    iteracted_items = items_train | items_test\n",
    "    non_interacted_items = list(total_items - iteracted_items)\n",
    "    if num_samples:\n",
    "      pool_of_items = sample(non_interacted_items, 99)\n",
    "    else: \n",
    "      pool_of_items = non_interacted_items\n",
    "    negative_samples.append(([(user, item)] + pool_of_items))\n",
    "\n",
    "  return negative_samples\n",
    "\n",
    "create_negative_sample(train_data, test_data, 'user', 'item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "train_data = df_frappe.train_ratings\n",
    "test_data = df_frappe.test_ratings\n",
    "\n",
    "train_data_grouped = train_data.groupby(['user', 'item']).count()\n",
    "total_items = set(test_data['item'].unique()) | set(train_data['item'].unique())\n",
    "negative_samples = []\n",
    "for user in test_data.user.unique():\n",
    "  items_train = set(train_data_grouped.loc[0].index)\n",
    "  items_test = set(test_data[test_data['user'] == user]['item'])\n",
    "  iteracted_items = items_train | items_test\n",
    "  non_interacted_items = list(total_items - iteracted_items)\n",
    "  pool_of_items = sample(non_interacted_items, 99)\n",
    "  negative_samples.append(([(user, item)] + random_elements))\n",
    "  \n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_grouped = train_data.groupby(['user', 'item']).count()\n",
    "total_items = set(test_data['item'].unique()) | set(train_data['item'].unique())\n",
    "negative_samples = []\n",
    "\n",
    "for row in test_data.iterrows():\n",
    "  user = int(row[1]['user'])\n",
    "  item = int(row[1]['item'])\n",
    "  items_train = set(train_data_grouped.loc[0].index)\n",
    "  items_test = set(test_data[test_data['user'] == user]['item'])\n",
    "  iteracted_items = items_train | items_test\n",
    "  non_interacted_items = list(total_items - iteracted_items)\n",
    "  pool_of_items = sample(non_interacted_items, 99)\n",
    "  negative_samples.append(([(user, item)] + pool_of_items))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
