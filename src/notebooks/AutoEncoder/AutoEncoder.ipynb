{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed Data\n",
    "import sys\n",
    "sys.path.append('/home/alexabades/recsys')\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import torch \n",
    "from torch import nn, optim \n",
    "import torch\n",
    "_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from src.models.AutoEncoder.AE import AutoEncoder\n",
    "from src.data.BinaryClassifictionDataLoader import ContextDataLoaderBinaryClasifictaion\n",
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "_optimizers = {\"adam\": optim.Adam, \"SGD\": optim.SGD}\n",
    "_loss_fn = {\"BCE\": nn.BCELoss(), \"MSE\": nn.MSELoss()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ReLU' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     13\u001b[0m hidden_units\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m21\u001b[39m, \u001b[38;5;241m9\u001b[39m]\n\u001b[0;32m---> 14\u001b[0m ae_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_units\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(_device)\n",
      "Cell \u001b[0;32mIn[12], line 60\u001b[0m, in \u001b[0;36mAutoEncoder.__init__\u001b[0;34m(self, hidden_dims, dropout, activation)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\u001b[38;5;241m*\u001b[39mencoder_layers)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\u001b[38;5;241m*\u001b[39mdecoder_layers, nn\u001b[38;5;241m.\u001b[39mSigmoid())\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 69\u001b[0m, in \u001b[0;36mAutoEncoder._init_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_init_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder:\n\u001b[0;32m---> 69\u001b[0m         nn\u001b[38;5;241m.\u001b[39minit\u001b[38;5;241m.\u001b[39mnormal_(\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m, mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, std\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder:\n\u001b[1;32m     71\u001b[0m         nn\u001b[38;5;241m.\u001b[39minit\u001b[38;5;241m.\u001b[39mnormal_(layer\u001b[38;5;241m.\u001b[39mweight, mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, std\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n",
      "File \u001b[0;32m~/recsys/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ReLU' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "from src.data.ContextDataLoader import ContextDataLoader\n",
    "\n",
    "\n",
    "train_data_path = \"../data/processed/frappeCtxA/frappeCtxA.train.rating\"\n",
    "test_data_path = \"../data/processed/frappeCtxA/frappeCtxA.test.rating\"\n",
    "train_data = ContextDataLoader(train_data_path)\n",
    "test_data = ContextDataLoader(test_data_path)\n",
    "\n",
    "# Dataloader\n",
    "train_loader = DataLoader(train_data, 100)\n",
    "test_loader = DataLoader(test_data, 100)\n",
    "epochs = 100\n",
    "hidden_units=[21, 9]\n",
    "ae_model = AutoEncoder(hidden_units).to(_device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=21, out_features=9, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=9, out_features=21, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=21, out_features=9, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=9, out_features=21, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for i in ae_model.modules():\n",
    "  print(i)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 22])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_tensor = torch.randint(0, 2, size=(256,22), dtype=torch.float32, device=_device)\n",
    "noise = torch.rand(256, 1)\n",
    "noise_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0462, 1.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
       "        [0.2514, 1.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.4606, 1.0000, 0.0000,  ..., 1.0000, 0.0000, 1.0000],\n",
       "        ...,\n",
       "        [0.3135, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 1.0000],\n",
       "        [0.1417, 0.0000, 1.0000,  ..., 0.0000, 1.0000, 0.0000],\n",
       "        [0.6579, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_tensor[:, 0] = noise.squeeze()\n",
    "noise_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ae_model.train()\n",
    "\n",
    "# Initialize Optimizer and Loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(ae_model.parameters(), lr=0.001)\n",
    "\n",
    "# calculate_memory_allocation()\n",
    "for epoch in range(epochs):\n",
    "    if not epoch % 10: \n",
    "        print(epoch)\n",
    "    for batch in train_loader:\n",
    "        context_input = batch[\"context\"].to(_device)\n",
    "        # TODO: Context should be floating point, at least cnt feature, what happens when is converted into long\n",
    "\n",
    "        output = ae_model(context_input)\n",
    "        loss = loss_fn(output[\"prediction\"], context_input)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11 % 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.eval import mean_absolute_error, root_mean_squared_error\n",
    "\n",
    "\n",
    "ae_model.eval()\n",
    "with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            context_input = batch[\"context\"].to(_device)\n",
    "\n",
    "\n",
    "            output = ae_model(context_input)\n",
    "            # Evaluate\n",
    "            rsme = root_mean_squared_error(output['prediction'], context_input)\n",
    "            mae = mean_absolute_error(output['prediction'], context_input)\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50970936"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/alexabades/recsys/src/notebooks'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.model_stats.stats import save_model_with_params\n",
    "chk_path = '/home/alexabades/recsys/src/notebooks/ae.bin'\n",
    "model_params = {\n",
    "    \"hidden_dims\": hidden_units,\n",
    "    \"dropout\": 0,\n",
    "    \"activation\": 'ReLU'\n",
    "}\n",
    "\n",
    "save_model_with_params(chk_path, ae_model, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_with_params(path):\n",
    "    checkpoint = torch.load(path)\n",
    "    model_params = checkpoint['model_params']\n",
    "\n",
    "    # Reconstruct the model based on saved parameters\n",
    "    # This assumes you have a way to map 'activation' from a string to an actual PyTorch activation function\n",
    "    activation_function = getattr(nn, model_params['activation']) if 'activation' in model_params else nn.ReLU\n",
    "    model = AutoEncoder(\n",
    "        hidden_dims=model_params['hidden_dims'],\n",
    "        dropout=model_params['dropout'],\n",
    "        activation=activation_function,\n",
    "    )\n",
    "    \n",
    "    # Load the saved state_dict into the model\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model_with_params(chk_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mmodules()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List\n",
    "import warnings\n",
    "from torch import nn\n",
    "\n",
    "# TODO: Initialize mean and standard deviation\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_dims: List[int] = None,\n",
    "        dropout: float = 0,\n",
    "        activation: Callable[..., nn.Module] = nn.ReLU,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Autoencoder following an hourglass structure\n",
    "\n",
    "        Parameters:\n",
    "          - hidden_dims (List[Ã¬nt]): List indicating the hideen dimensions of the Encoder\n",
    "          - dropout (float): Droput for all hidden layers\n",
    "          - activation (Callable): Activation function, default to ReLU\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        if not hidden_dims:\n",
    "            raise ValueError(\"AutoEncoder initialized without dimensions\")\n",
    "        if len(hidden_dims) < 2:\n",
    "            warnings.warn(\"AutoEncoder with a single hidden layer.\")\n",
    "\n",
    "        # Build the encoder layers\n",
    "        encoder_layers = []\n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            encoder_layers.extend(\n",
    "                [\n",
    "                    nn.Linear(hidden_dims[i], hidden_dims[i + 1]),\n",
    "                    activation(),\n",
    "                    nn.Dropout(dropout),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        # Build the decoder layers (reverse structure of the encoder)\n",
    "        decoder_layers = []\n",
    "        decoder_dims = hidden_dims[::-1]  # Reverse the dimensions for the decoder\n",
    "        for i in range(len(decoder_dims) - 1):\n",
    "            decoder_layers.extend(\n",
    "                [\n",
    "                    nn.Linear(decoder_dims[i], decoder_dims[i + 1]),\n",
    "                    activation(),\n",
    "                    nn.Dropout(dropout),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        # Removing the last Dropout from the encoder and decoder\n",
    "        encoder_layers = encoder_layers[:-1]\n",
    "        decoder_layers = decoder_layers[:-1]\n",
    "\n",
    "        self.encoder = nn.Sequential(*encoder_layers)\n",
    "        self.decoder = nn.Sequential(*decoder_layers, nn.Sigmoid())\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        return {\"latent\": z, \"prediction\": x_hat}\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for module in self.modules():\n",
    "            # print(module)\n",
    "            if isinstance(module, nn.Linear):\n",
    "                print(module.weight)\n",
    "                nn.init.normal_(module.weight, mean=0.0, std=0.01)\n",
    "                print(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(\n",
    "                        module.bias, 0\n",
    "                    )  # Optionally initialize biases to 0\n",
    "\n",
    "    # def _init_weights(self):\n",
    "    #     for layer in self.encoder:\n",
    "    #         nn.init.normal_(layer.weight, mean=0.0, std=0.01)\n",
    "    #     for layer in self.decoder:\n",
    "    #         nn.init.normal_(layer.weight, mean=0.0, std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1380,  0.0920,  0.1286, -0.1268, -0.1782,  0.2025, -0.0457,  0.0156,\n",
      "          0.1342, -0.1020,  0.1070,  0.1477, -0.1106, -0.0763, -0.2079, -0.0231,\n",
      "         -0.0884, -0.0955,  0.1448, -0.1253,  0.0222, -0.0599],\n",
      "        [-0.0028, -0.0679,  0.1249,  0.1438,  0.1213,  0.1215, -0.1145,  0.0598,\n",
      "          0.0084,  0.0961, -0.0105,  0.1192, -0.1957,  0.0996, -0.0661, -0.1028,\n",
      "          0.0415,  0.2097, -0.1590, -0.1220, -0.1909, -0.1629],\n",
      "        [-0.0182,  0.1747,  0.0559,  0.2077,  0.0119,  0.1330,  0.1812,  0.1886,\n",
      "         -0.0842, -0.0272, -0.0377, -0.2023,  0.0162, -0.0511,  0.1733,  0.0944,\n",
      "          0.0859, -0.1093, -0.2095, -0.2083, -0.1753,  0.0903],\n",
      "        [ 0.0979, -0.1212, -0.1360,  0.1611, -0.1027,  0.1105, -0.0692, -0.0717,\n",
      "          0.0216,  0.0846,  0.0263,  0.1416, -0.1616, -0.1455,  0.1220,  0.1633,\n",
      "         -0.1788, -0.0649,  0.1084, -0.1242,  0.2046, -0.0998],\n",
      "        [-0.0326, -0.0544,  0.1637, -0.1932,  0.0180,  0.0595, -0.1286, -0.0923,\n",
      "          0.0965, -0.0681, -0.1553,  0.0348,  0.1116,  0.1562,  0.1778,  0.1533,\n",
      "         -0.0190, -0.0514, -0.0291, -0.1452,  0.2093,  0.1034],\n",
      "        [ 0.1333,  0.0508, -0.0041,  0.0332, -0.0093, -0.0171, -0.1371, -0.0950,\n",
      "         -0.0325, -0.1753, -0.0190, -0.1696,  0.0467,  0.1311, -0.1868,  0.1357,\n",
      "         -0.1642,  0.2056, -0.1177,  0.1903,  0.1178, -0.1724],\n",
      "        [ 0.1238, -0.0019, -0.0509,  0.0911,  0.1460, -0.0536, -0.0879,  0.1145,\n",
      "          0.0204, -0.0733, -0.1541,  0.0757,  0.2068, -0.0386, -0.0948, -0.1734,\n",
      "         -0.1079, -0.1973,  0.0234, -0.1524, -0.0660, -0.1056],\n",
      "        [ 0.1235, -0.1495, -0.0070,  0.1792,  0.1645,  0.1758, -0.1680,  0.0153,\n",
      "         -0.0201,  0.1869,  0.1630,  0.0403,  0.0405,  0.0837, -0.1209, -0.0205,\n",
      "         -0.0148,  0.0226, -0.1595,  0.0535, -0.1567,  0.1278],\n",
      "        [ 0.0512,  0.0638, -0.1083,  0.0259,  0.1830, -0.1338,  0.1225,  0.1411,\n",
      "          0.1021, -0.1625,  0.1623,  0.1023,  0.0445, -0.0221,  0.1416, -0.0580,\n",
      "          0.1046,  0.1066, -0.1311, -0.0065, -0.0534,  0.0858]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.8717e-02, -9.0505e-03,  1.3698e-02,  4.7817e-03,  8.4732e-03,\n",
      "         -9.3699e-03,  2.4222e-02,  2.7927e-02, -5.0081e-03,  3.4163e-03,\n",
      "          1.4518e-02,  7.7278e-03, -2.5977e-03,  1.1652e-02, -4.9056e-03,\n",
      "         -1.5912e-03, -2.0151e-02,  9.1557e-03,  4.4908e-03,  1.4799e-03,\n",
      "         -3.6991e-03,  1.1065e-02],\n",
      "        [-2.5009e-02,  1.1550e-02,  1.3132e-02, -1.2834e-03, -4.6704e-03,\n",
      "          9.2577e-04, -1.9758e-02, -9.9601e-03,  1.1320e-02,  1.1663e-03,\n",
      "          2.2061e-03,  4.6386e-03, -1.2490e-02,  6.5946e-04, -9.2639e-03,\n",
      "         -1.1350e-02,  1.4547e-02, -1.7206e-02,  8.7777e-04,  1.1273e-02,\n",
      "          1.3984e-02,  2.0152e-02],\n",
      "        [-3.3240e-03, -1.0631e-03, -2.5259e-03, -8.0583e-03,  1.6764e-02,\n",
      "          6.5166e-03,  7.6485e-03,  3.1158e-03,  2.8122e-03,  1.4798e-02,\n",
      "          1.9765e-02, -3.6440e-03,  1.1360e-02, -1.0282e-02,  3.2433e-03,\n",
      "          8.3267e-03, -1.9921e-02,  1.6834e-03,  1.4275e-02, -1.0542e-02,\n",
      "         -9.9008e-03,  5.9110e-03],\n",
      "        [-2.6131e-02, -1.3439e-02,  1.0594e-02, -2.3432e-02, -7.8032e-03,\n",
      "          9.3857e-03, -7.7094e-03,  1.6360e-02,  1.7617e-04,  7.1203e-03,\n",
      "          3.2647e-03,  8.4161e-03, -1.1702e-03, -6.3937e-03,  4.9139e-03,\n",
      "          1.6103e-02, -2.0972e-03,  1.3320e-02, -6.5104e-03, -4.1779e-03,\n",
      "          1.5460e-03,  7.3952e-03],\n",
      "        [-4.1156e-03,  9.3142e-03,  3.3744e-03, -2.0533e-04,  8.7971e-03,\n",
      "         -8.9650e-03, -1.1080e-02,  2.5024e-03, -4.3032e-03, -1.1269e-03,\n",
      "          1.1529e-03, -9.7059e-03, -8.9168e-03,  2.8489e-03, -2.7238e-03,\n",
      "          3.3342e-03, -1.6697e-02,  4.8958e-03, -8.6355e-03, -2.2008e-02,\n",
      "         -3.5711e-03,  1.1590e-03],\n",
      "        [-1.3983e-02, -1.3134e-02, -3.1912e-04, -1.3909e-02, -9.8739e-03,\n",
      "          2.6374e-03, -1.3301e-02,  8.6846e-03, -8.3419e-04,  1.7750e-02,\n",
      "          8.6061e-04, -1.0658e-02, -2.6780e-02, -1.1046e-02, -1.6709e-02,\n",
      "          9.8327e-03, -1.2201e-02, -6.0049e-03, -3.5229e-03,  6.4581e-03,\n",
      "         -3.0988e-04,  8.7895e-03],\n",
      "        [ 9.3181e-04, -8.0658e-03, -3.0170e-03,  5.7591e-03, -1.0859e-02,\n",
      "          4.1783e-03, -1.5252e-02, -9.1508e-03,  8.1826e-04,  3.0475e-04,\n",
      "         -4.3755e-03,  3.6279e-03, -3.7036e-03,  6.2221e-03,  1.9034e-02,\n",
      "          8.9425e-03,  1.5022e-02, -2.1094e-02, -1.3664e-02,  9.5296e-03,\n",
      "          2.8199e-03,  3.6610e-03],\n",
      "        [ 4.8058e-03, -1.3559e-03, -1.5354e-03, -1.6107e-02,  1.0136e-02,\n",
      "         -4.4537e-03, -2.0768e-03,  1.2809e-02, -1.5098e-02, -7.0029e-04,\n",
      "         -9.2357e-03, -1.9472e-05,  1.0711e-02,  4.5295e-03, -1.2736e-03,\n",
      "          2.1623e-02, -1.8284e-02, -9.5989e-03, -5.9407e-03,  1.8096e-02,\n",
      "          1.6616e-03, -6.4497e-03],\n",
      "        [-3.1356e-03,  1.5129e-02, -3.3719e-03,  3.1362e-03,  4.4973e-03,\n",
      "         -1.1012e-02, -6.2120e-03, -3.8134e-03,  6.7473e-03, -4.6724e-03,\n",
      "          2.2096e-03, -4.2399e-03, -1.3230e-02,  8.4496e-03, -8.4080e-04,\n",
      "          2.6605e-03, -1.6770e-02,  5.7756e-03,  1.0204e-02, -1.0657e-02,\n",
      "          2.4350e-02, -2.5931e-03]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0334,  0.2987, -0.2861, -0.2195,  0.1112, -0.2728, -0.1387, -0.1903,\n",
      "         -0.2638],\n",
      "        [ 0.1851,  0.2641, -0.0922,  0.0038, -0.2514,  0.0740, -0.1980, -0.0068,\n",
      "         -0.2019],\n",
      "        [-0.3130, -0.1085,  0.0396, -0.0835,  0.0885, -0.2256,  0.0972,  0.1618,\n",
      "         -0.1004],\n",
      "        [ 0.2987, -0.0885, -0.2526, -0.0590, -0.1395, -0.1001, -0.2620,  0.2384,\n",
      "          0.1171],\n",
      "        [ 0.0010, -0.0197,  0.2566,  0.0410, -0.0416,  0.3167, -0.2397, -0.0542,\n",
      "         -0.0705],\n",
      "        [ 0.2399,  0.0992, -0.2766, -0.2064,  0.2635, -0.0301, -0.1888, -0.2071,\n",
      "         -0.1362],\n",
      "        [-0.3131, -0.0244, -0.0049, -0.1970, -0.1052,  0.1223,  0.2353,  0.2707,\n",
      "          0.2402],\n",
      "        [ 0.1180,  0.3275,  0.2232, -0.2587, -0.0659,  0.0345,  0.0989,  0.1862,\n",
      "         -0.2355],\n",
      "        [-0.2483,  0.1942, -0.1421,  0.0982,  0.0727,  0.0698,  0.2604, -0.1832,\n",
      "         -0.1884],\n",
      "        [ 0.2593,  0.1983,  0.1368,  0.0704, -0.0901,  0.2440,  0.1206, -0.1734,\n",
      "          0.0541],\n",
      "        [-0.2993,  0.1028, -0.0912,  0.2435,  0.1934, -0.2392, -0.2733,  0.0500,\n",
      "         -0.1846],\n",
      "        [ 0.3331, -0.2252, -0.0444, -0.1883,  0.3236, -0.2018,  0.0736, -0.2033,\n",
      "          0.2618],\n",
      "        [-0.1479, -0.0729, -0.3333,  0.3026, -0.0448, -0.3154,  0.2523,  0.2272,\n",
      "          0.3272],\n",
      "        [-0.2028, -0.3037,  0.0671, -0.0499,  0.2675,  0.1510, -0.2012, -0.1674,\n",
      "         -0.0208],\n",
      "        [ 0.0196, -0.2643, -0.2218,  0.0859,  0.3236, -0.2560,  0.2013,  0.2718,\n",
      "          0.2422],\n",
      "        [ 0.1573,  0.0990, -0.2871, -0.1260, -0.1362,  0.0390, -0.1005, -0.1162,\n",
      "          0.2881],\n",
      "        [ 0.0940,  0.1864,  0.0808,  0.1825,  0.3047, -0.0114,  0.3040, -0.2962,\n",
      "         -0.0280],\n",
      "        [-0.3200,  0.2490,  0.0446, -0.3243, -0.1580,  0.1315,  0.1732, -0.0046,\n",
      "          0.1251],\n",
      "        [ 0.0142, -0.2255, -0.0651, -0.0668,  0.0409,  0.2132, -0.0093,  0.2758,\n",
      "         -0.0438],\n",
      "        [-0.0654,  0.2789, -0.2196, -0.2285,  0.2765,  0.1236, -0.1544,  0.2365,\n",
      "          0.0609],\n",
      "        [-0.1194, -0.2029,  0.0578, -0.0404, -0.1004, -0.2598, -0.1498,  0.0952,\n",
      "          0.2567],\n",
      "        [-0.3261,  0.2469, -0.3241,  0.2768, -0.2737,  0.1364, -0.1173, -0.0130,\n",
      "         -0.2534]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 3.2351e-03, -1.4073e-02, -1.5920e-02,  9.9834e-03,  1.3753e-02,\n",
      "         -1.0190e-04,  1.5053e-02,  3.1564e-03,  7.5178e-03],\n",
      "        [ 1.1909e-02,  6.1001e-03, -1.3954e-02, -1.3865e-02,  1.5080e-02,\n",
      "         -1.8992e-02, -1.5580e-03,  1.7907e-02,  1.0101e-02],\n",
      "        [-2.0539e-03,  5.9456e-03,  5.4497e-03,  6.5666e-03,  3.8464e-03,\n",
      "          1.1161e-02,  1.8787e-02,  7.3055e-03,  8.5110e-03],\n",
      "        [ 7.2094e-03, -2.3340e-02,  1.1157e-02,  6.3968e-03,  2.1811e-02,\n",
      "         -1.6588e-02,  1.0096e-02,  2.3521e-02,  6.3172e-03],\n",
      "        [ 1.2072e-02,  1.4438e-02,  5.8838e-04,  1.2680e-02,  3.2321e-03,\n",
      "         -3.2455e-03,  4.1482e-03,  3.5936e-03,  3.3357e-03],\n",
      "        [-6.6073e-04,  4.0584e-03, -1.0815e-02,  4.2750e-03, -7.4201e-04,\n",
      "          3.0454e-03,  5.0701e-03,  9.5131e-03,  1.2057e-02],\n",
      "        [ 1.4806e-03,  5.6266e-03,  6.1393e-03, -4.4501e-03,  1.1099e-02,\n",
      "         -3.7105e-03, -2.5030e-02, -4.0709e-03,  7.0332e-03],\n",
      "        [ 8.5739e-03, -7.0164e-03, -1.1866e-03,  1.7616e-02, -1.0451e-02,\n",
      "         -6.9977e-03, -3.5693e-03, -3.3367e-03, -5.9924e-03],\n",
      "        [ 5.7544e-03,  1.2967e-02, -7.3079e-03, -8.1230e-03,  1.2465e-02,\n",
      "          2.6565e-03,  2.6377e-03,  1.3886e-02,  9.3977e-03],\n",
      "        [-1.3864e-03,  1.7733e-02,  1.3620e-02,  1.1782e-02,  1.5962e-03,\n",
      "          3.4752e-03, -4.5235e-04, -4.5357e-05,  4.6656e-03],\n",
      "        [-6.2643e-03, -8.8409e-03,  9.6225e-03,  2.0551e-04,  1.8446e-02,\n",
      "         -1.1353e-02, -6.8741e-03,  3.7821e-03, -9.8095e-03],\n",
      "        [-4.0358e-03, -5.2623e-04, -9.5295e-03, -4.0541e-03, -1.4558e-02,\n",
      "          3.8763e-03, -4.4219e-03,  2.2148e-02,  2.1005e-02],\n",
      "        [-5.6533e-03, -3.1266e-03, -7.2466e-03,  6.4560e-03, -1.0604e-04,\n",
      "         -4.1528e-03,  8.4966e-03,  7.0877e-03,  9.2466e-03],\n",
      "        [ 1.0536e-02,  2.3669e-02,  5.3530e-03,  7.6479e-03,  8.1148e-04,\n",
      "          1.2277e-02, -1.5049e-02, -5.8269e-03, -6.0229e-03],\n",
      "        [-2.7987e-03,  9.7650e-03, -5.6914e-03,  1.3783e-03,  8.5697e-04,\n",
      "         -1.3349e-02, -4.4319e-04, -1.8496e-03, -1.0015e-03],\n",
      "        [-1.1501e-02, -3.2027e-02,  1.5484e-03, -8.3324e-03, -2.1347e-02,\n",
      "         -8.7588e-03,  9.6292e-03, -6.6525e-03, -1.2242e-02],\n",
      "        [ 2.3279e-03,  2.1321e-02,  1.0768e-02, -8.1754e-03,  2.6729e-03,\n",
      "          2.0861e-02,  5.8786e-03,  1.5098e-02,  1.6938e-02],\n",
      "        [ 8.9763e-03, -2.0756e-03, -1.0384e-03,  1.3563e-03,  2.3096e-03,\n",
      "         -1.8078e-02,  2.9039e-03, -1.4397e-02, -1.1469e-02],\n",
      "        [ 3.6075e-03, -1.2867e-02, -6.3870e-03,  5.9308e-03, -1.5221e-03,\n",
      "          2.0142e-02,  5.2843e-03, -9.3150e-03, -6.6998e-03],\n",
      "        [ 1.2508e-02,  4.2991e-03, -2.6335e-03, -1.0004e-02, -3.7188e-03,\n",
      "         -1.1700e-02, -5.1103e-04,  1.0331e-02, -4.1351e-03],\n",
      "        [-4.4956e-04,  5.6383e-04,  2.1289e-03,  3.1300e-03, -1.4965e-02,\n",
      "         -1.3216e-02, -8.9860e-03,  6.9947e-03,  1.1785e-03],\n",
      "        [-3.9489e-03,  1.9956e-02,  5.6815e-03,  1.5681e-03, -9.2100e-04,\n",
      "          1.1297e-02,  3.9550e-03,  1.7708e-02, -1.4376e-03]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = AutoEncoder([22,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.modules at 0x7fb300f4c120>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.modules()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
