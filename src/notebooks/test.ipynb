{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/alexabades/recsys')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "start = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8515099962552388"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(end-start)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.mlp.mlp import MLP\n",
    "\n",
    "EMBEDDING_SIZE = 3\n",
    "N_USERS = 5\n",
    "N_ITEMS = 10\n",
    "a = MLP(2*EMBEDDING_SIZE, N_ITEMS, [6, 4, 2], dropout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = [32, 23,45]\n",
    "[int(layers[0] / 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import dok_matrix\n",
    "S = dok_matrix((2, 2), dtype=np.float32)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        \n",
    "          S[i, j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n",
      "  (0, 1)\t1.0\n",
      "  (1, 0)\t1.0\n",
      "  (1, 1)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([(0, 0), (0, 1), (1, 0), (1, 1)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "movies_path = '../data/ml-1m/movies.dat'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MovieID                               Title                        Genres\n",
       "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4        5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example paths, adjust as necessary\n",
    "ratings_path = '../data/ml-1m/ratings.dat'\n",
    "users_path = '../data/ml-1m/users.dat'\n",
    "movies_path = '../data/ml-1m/movies.dat'\n",
    "\n",
    "# Load the data\n",
    "ratings = pd.read_csv(ratings_path, sep='::', engine='python', names=['UserID', 'MovieID', 'Rating', 'Timestamp'])\n",
    "users = pd.read_csv(users_path, sep='::', engine='python', names=['UserID', 'Gender', 'Age', 'Occupation', 'Zip-code'])\n",
    "movies = pd.read_csv(movies_path, sep='::', engine='python', encoding='ISO-8859-1', names=['MovieID', 'Title', 'Genres'])\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_dt, test = train_test_split(ratings, test_size=0.2, random_state=42)\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, ratings):\n",
    "        self.users = torch.tensor(ratings['UserID'].values, dtype=torch.long)\n",
    "        self.items = torch.tensor(ratings['MovieID'].values, dtype=torch.long)\n",
    "        self.ratings = torch.tensor(ratings['Rating'].values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.ratings[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(ratings, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def save_accuracy(filepath:str, **kwargs):\n",
    "    \n",
    "    with open('acuracy.json', 'w') as file:\n",
    "        json.dump(kwargs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"./src/checkpoints/nfc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_accuracy(filepath, a=5, b=3, c=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Timestamp\n",
       "0       1     1193       5  978300760"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings2 = ratings[0:80]\n",
    "ratings2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserID            6040\n",
       "MovieID           1097\n",
       "Rating               4\n",
       "Timestamp    956715569\n",
       "Name: 1000208, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3705, 6039)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_path = \"../data/processed/ml-1m.train.rating\"\n",
    "ratings = pd.read_csv(ratings_path, sep='\\t', engine='python', names=['UserID', 'MovieID', 'Rating', 'Timestamp'])\n",
    "\n",
    "ratings[\"MovieID\"].max(), ratings[\"UserID\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "num_users, num_items = 0, 0\n",
    "with open(ratings_path, \"r\") as f:\n",
    "    line = f.readline()\n",
    "    \n",
    "    while line != None and line != \"\":\n",
    "        arr = line.split(\"\\t\")\n",
    "        u, i = int(arr[0]), int(arr[1])\n",
    "        num_users = max(num_users, u)\n",
    "        num_items = max(num_items, i)\n",
    "        line = f.readline()\n",
    "# Construct matrix\n",
    "mat = sp.dok_matrix((num_users+1, num_items+1), dtype=np.float32)\n",
    "with open(ratings_path, \"r\") as f:\n",
    "    line = f.readline()\n",
    "    while line != None and line != \"\":\n",
    "        arr = line.split(\"\\t\")\n",
    "        user, item, rating = int(arr[0]), int(arr[1]), float(arr[2])\n",
    "        if (rating > 0):\n",
    "            mat[user, item] = 1.0\n",
    "        line = f.readline()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "895536    5412\n",
       "899739    5440\n",
       "55687      368\n",
       "63727      425\n",
       "822011    4942\n",
       "          ... \n",
       "756007    4505\n",
       "477775    2934\n",
       "424188    2572\n",
       "293600    1748\n",
       "149989     965\n",
       "Name: UserID, Length: 200042, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"MovieID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5412, 2683],\n",
       "        [5440,  904],\n",
       "        [ 368, 3717],\n",
       "        ...,\n",
       "        [2572,  968],\n",
       "        [1748, 1625],\n",
       "        [ 965, 1233]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_list = list(zip(test['UserID'], test['MovieID']))\n",
    "torch.tensor(pairs_list, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/home/alexabades/recsys')\n",
    "from src.data.DataLoader import MovieLensDataset\n",
    "data = MovieLensDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/processed/ml-1m/ml-1m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = [1,2,3]\n",
    "b = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.extend(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.load_processed_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "u = 4\n",
    "items = [1]*20\n",
    "users = np.full(len(items), u, dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UserID', 'MovieID', 'Rating', 'Timestamp'], dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dt = ratings[:400]\n",
    "train_dt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_instances(train, num_negatives):\n",
    "    user_input, item_input, labels = [],[],[]\n",
    "    num_users = train.shape[1]\n",
    "    for (u, i) in train.keys():\n",
    "        # positive instance\n",
    "        user_input.append(u)\n",
    "        item_input.append(i)\n",
    "        labels.append(1)\n",
    "        # negative instances\n",
    "        for t in range(num_negatives):\n",
    "            j = np.random.randint(num_items)\n",
    "            while train.has_key((u, j)):\n",
    "                j = np.random.randint(num_items)\n",
    "            user_input.append(u)\n",
    "            item_input.append(j)\n",
    "            labels.append(0)\n",
    "    return user_input, item_input, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from typing import Tuple, List\n",
    "\n",
    "def get_train_instances(train:sp.dok_matrix, num_negatives: int) -> Tuple[List[int], List[int], List[int]]:\n",
    "    \"\"\"\n",
    "    Create nº Negative instances per postive instance in the matrix.\n",
    "\n",
    "    Args:\n",
    "        - train: Train sparse matrix storing the positive instances fro pairs (n_users, n_items).\n",
    "        - num_negatives: The number of negative instances we want to generate per positive instacne.\n",
    "    Reruns:\n",
    "        - user_input: List of User IDs \n",
    "        - item_input: List of Items IDs\n",
    "        - labels: Binary List determine Positive or Negative Instance\n",
    "    \"\"\"\n",
    "    user_input, item_input, labels = [], [], []\n",
    "    num_items = train.shape[1]\n",
    "    # Iterate over all non-zero elements in the sparse matrix\n",
    "    # which are the positive instances\n",
    "    train_coo = train.tocoo()  # Convert to COO format for easy iteration\n",
    "    for u, i in zip(train_coo.row, train_coo.col):\n",
    "        # positive instance\n",
    "        user_input.append(u)\n",
    "        item_input.append(i)\n",
    "        labels.append(1)\n",
    "        \n",
    "        # negative instances\n",
    "        for _ in range(num_negatives):\n",
    "            j = np.random.randint(num_items)\n",
    "            # Keep generating a new negative item until we find one that \n",
    "            # the user has not interacted with\n",
    "            while train[u, j] != 0:\n",
    "                j = np.random.randint(num_items)\n",
    "            user_input.append(u)\n",
    "            item_input.append(j)\n",
    "            labels.append(0)\n",
    "    \n",
    "    return user_input, item_input, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input, item_input, labels = get_train_instances(mat, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6039"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_train_instances(train, num_items, num_negatives):\n",
    "        user_input, item_input, labels = [], [], []\n",
    "        num_users = train.shape[0]\n",
    "\n",
    "        # Assuming 'train' is a dictionary with keys as (user, item) tuples\n",
    "        for u, i in train.keys():\n",
    "            # positive instance\n",
    "            user_input.append(u)\n",
    "            item_input.append(i)\n",
    "            labels.append(1)\n",
    "\n",
    "            # negative instances\n",
    "            for _ in range(num_negatives):\n",
    "                j = np.random.randint(num_items)\n",
    "                while (u, j) in train:\n",
    "                    j = np.random.randint(num_items)\n",
    "                user_input.append(u)\n",
    "                item_input.append(j)\n",
    "                labels.append(0)\n",
    "\n",
    "        # Converting lists to PyTorch tensors\n",
    "        user_input = torch.tensor(user_input, dtype=torch.long)\n",
    "        item_input = torch.tensor(item_input, dtype=torch.long)\n",
    "        labels = torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "        return user_input, item_input, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6040x3706 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 994169 stored elements in Dictionary Of Keys format>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22384240"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Sparse Tensor: tensor(indices=tensor([[0, 1, 2],\n",
      "                       [2, 0, 3]]),\n",
      "       values=tensor([1, 2, 3]),\n",
      "       size=(3, 4), nnz=3, layout=torch.sparse_coo)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[2]]),\n",
       "       values=tensor([1]),\n",
       "       size=(4,), nnz=1, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define the initial non-zero elements and their indices\n",
    "initial_indices = torch.tensor([[0, 1, 2], [2, 0, 3]]) # Shape [2, N] where N is the number of non-zero elements\n",
    "initial_values = torch.tensor([1, 2, 3])  # Non-zero values corresponding to the indices\n",
    "\n",
    "# Define the size of the sparse tensor\n",
    "size = torch.Size([3, 4])  # For example, a 3x4 matrix\n",
    "\n",
    "# Create the initial sparse tensor\n",
    "sparse_tensor = torch.sparse_coo_tensor(initial_indices, initial_values)\n",
    "print(\"Initial Sparse Tensor:\", sparse_tensor)\n",
    "\n",
    "sparse_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6039, 3705)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users, num_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "class MovieLensDataset(Dataset):\n",
    "  def __init__(self, path:str, test_size:float=0.2, num_negatives:int=4) -> None:\n",
    "    self.ratings = self._load_datasets(path)\n",
    "    self.negative = \"TODO\"\n",
    "    self.traindatset, self.testdataset = self._split_traintest(test_size)\n",
    "    self.trainMartrix = self.trainMx(self.traindatset)\n",
    "    self.test = \"TODO\"\n",
    "    self.path = path \n",
    "    self.num_negatives = num_negatives\n",
    "\n",
    "  def _load_datasets(self, ratings_path:str) ->pd.DataFrame:\n",
    "    return pd.read_csv(ratings_path, sep='::', engine='python', names=['UserID', 'MovieID', 'Rating', 'Timestamp'])\n",
    "\n",
    "  def _split_traintest(self, test_size: float) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Funtion that splits the dataser into train/test with a specific test size and a fixed seed for repr.\n",
    "\n",
    "    Args:\n",
    "      - test_size: float indicating the % of split of the data\n",
    "    \"\"\"\n",
    "    train, test = train_test_split(self.ratings, test_size=test_size, random_state=42)\n",
    "    return train, test\n",
    "  \n",
    "  def trainMx(self, train_dt: pd.DataFrame) -> sp.dok_matrix:    \n",
    "    \"\"\"\n",
    "    Function that iterates through the dataset and generates a sparse matrix\n",
    "\n",
    "    Args: \n",
    "      - train_dt: trainig data to prepare to sparse matrix\n",
    "    Returns: \n",
    "      - sparse matrix storing the positive instances for pairs (n_users, n_items).\n",
    "    \"\"\"\n",
    "    num_users = train_dt[\"UserID\"].max()\n",
    "    num_items = train_dt[\"MovieID\"].max()\n",
    "    # Construct matrix: Look out indexing\n",
    "    mat = sp.dok_matrix((num_users+1, num_items+1), dtype=np.float32)\n",
    "    # Ensure that no 0 or lack of feedback is parsed as positve\n",
    "    for _, row in train_dt.iterrows():\n",
    "        user, item, rating = int(row['UserID']), int(row['MovieID']), float(row['Rating'])\n",
    "        if rating > 0:\n",
    "            mat[user, item] = 1.0\n",
    "    return mat\n",
    "  \n",
    "  def get_train_instances(self, train:sp.dok_matrix, num_negatives: int) -> Tuple[List[int], List[int], List[int]]:\n",
    "    \"\"\"\n",
    "    Create nº Negative instances per postive instance in the matrix.\n",
    "\n",
    "    Args:\n",
    "        - train: sparse matrix storing the positive instances for pairs (n_users, n_items).\n",
    "        - num_negatives: The number of negative instances we want to generate per positive instacne.\n",
    "    Reruns:\n",
    "        - user_input: List of User IDs \n",
    "        - item_input: List of Items IDs\n",
    "        - labels: Binary List determine Positive or Negative Instance\n",
    "    \"\"\"\n",
    "    user_input, item_input, labels = [], [], []\n",
    "    num_items = train.shape[1]\n",
    "    # Iterate over all non-zero elements in the sparse matrix\n",
    "    # which are the positive instances\n",
    "    train_coo = train.tocoo()  # Convert to COO format for easy iteration\n",
    "    for u, i in zip(train_coo.row, train_coo.col):\n",
    "        # positive instance\n",
    "        user_input.append(u)\n",
    "        item_input.append(i)\n",
    "        labels.append(1)\n",
    "        \n",
    "        # negative instances\n",
    "        for _ in range(num_negatives):\n",
    "            j = np.random.randint(num_items)\n",
    "            # Keep generating a new negative item until we find one that \n",
    "            # the user has not interacted with\n",
    "            while train[u, j] != 0:\n",
    "                j = np.random.randint(num_items)\n",
    "            user_input.append(u)\n",
    "            item_input.append(j)\n",
    "            labels.append(0)\n",
    "    \n",
    "   \n",
    "    return user_input, item_input, labels\n",
    "  \n",
    "  def get_train(self):\n",
    "    \"\"\"\n",
    "    Funtion that creates the necessary data to train the model. \n",
    "\n",
    "    Returns:\n",
    "      - user_input: Tensor of dimensions (nº of UserdId x nº of ratigs per user x nº of negative samples + 1) | Also:  (length of train dataset * 5)\n",
    "      - item_input: Tensor of dimensions (nº of UserdId x nº of ratigs per user x nº of negative samples + 1) | Also:  (length of train dataset * 5)\n",
    "      - labels: Tensor of dimensions (nº of UserdId x nº of ratigs per user x nº of negative samples + 1) | Also:  (length of train dataset * 5)\n",
    "    \"\"\"\n",
    "    \n",
    "    user_input, item_input, labels = self.get_train_instances(self.trainMartrix, self.num_negatives)\n",
    "     # Converting lists to PyTorch tensors\n",
    "    user_input = torch.tensor(user_input, dtype=torch.long)\n",
    "    item_input = torch.tensor(item_input, dtype=torch.long)\n",
    "    labels = torch.tensor(labels, dtype=torch.float)\n",
    "    \n",
    "    return user_input, item_input, labels\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_path = '../data/ml-1m/ratings.dat'\n",
    "data = MovieLensDataset(ratings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input, item_input, labels = data.get_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000835"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dims = [64,32,16,8]\n",
    "layers = []\n",
    "for layer in range(len(hidden_dims)-1):\n",
    "            layers.append((hidden_dims[layer], hidden_dims[layer+1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(64, 32), (32, 16), (16, 8)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
